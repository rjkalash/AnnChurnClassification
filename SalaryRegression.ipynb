{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1126d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90cdcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d384284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "input_data=df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "# One-hot encode 'Geography' column\n",
    "ohe_geography = OneHotEncoder(drop='first', sparse_output=False)\n",
    "input_data_array = ohe_geography.fit_transform(input_data[['Geography']])\n",
    "input_data_array_df=pd.DataFrame(input_data_array, columns=ohe_geography.get_feature_names_out(['Geography']))\n",
    "input_data=pd.concat([input_data, input_data_array_df], axis=1)\n",
    "input_data.drop(['Geography'], axis=1, inplace=True)\n",
    "\n",
    "# Label encode 'Gender' column\n",
    "le_gender = LabelEncoder()\n",
    "input_data['Gender'] = le_gender.fit_transform(input_data['Gender'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = input_data.drop('EstimatedSalary', axis=1).values\n",
    "y = input_data['EstimatedSalary'].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f5402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler, encoders\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('ohe_geography.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe_geography, f)\n",
    "with open('le_gender.pkl', 'wb') as f:\n",
    "    pickle.dump(le_gender, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4de0e140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
       "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
       "       'Geography_Germany', 'Geography_Spain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f88f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,881</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,881\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,881</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,881\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Ann For Regression Problem\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)  # No activation function for regression output\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36c39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback, TensorBoard callback added\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "log_dir = 'regression_logs/fit/'+pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a713a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13309078528.0000 - mae: 99982.4219 - val_loss: 13699265536.0000 - val_mae: 102045.0312\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13244442624.0000 - mae: 99659.5078 - val_loss: 13563408384.0000 - val_mae: 101381.3516\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13002397696.0000 - mae: 98451.4297 - val_loss: 13186741248.0000 - val_mae: 99543.6484\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12481148928.0000 - mae: 95856.3203 - val_loss: 12491746304.0000 - val_mae: 96144.1328\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11640210432.0000 - mae: 91685.1484 - val_loss: 11473408000.0000 - val_mae: 91107.5391\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10503128064.0000 - mae: 86046.7812 - val_loss: 10183847936.0000 - val_mae: 84702.4609\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9164021760.0000 - mae: 79314.0312 - val_loss: 8746071040.0000 - val_mae: 77445.2656\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7754941952.0000 - mae: 72215.6562 - val_loss: 7314040320.0000 - val_mae: 70225.9297\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6431262208.0000 - mae: 65564.8906 - val_loss: 6031959552.0000 - val_mae: 63699.3164\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5323938304.0000 - mae: 59967.6016 - val_loss: 5013959680.0000 - val_mae: 58496.7344\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4508549632.0000 - mae: 55809.6484 - val_loss: 4312252416.0000 - val_mae: 54834.1484\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3984923136.0000 - mae: 53066.9102 - val_loss: 3883316736.0000 - val_mae: 52555.7188\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3690876672.0000 - mae: 51598.8867 - val_loss: 3647916544.0000 - val_mae: 51323.5898\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3543442432.0000 - mae: 50850.7734 - val_loss: 3528494592.0000 - val_mae: 50723.5000\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3472635392.0000 - mae: 50481.8164 - val_loss: 3469602304.0000 - val_mae: 50408.6797\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3436338176.0000 - mae: 50292.8594 - val_loss: 3437373952.0000 - val_mae: 50228.8398\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3416252416.0000 - mae: 50189.3867 - val_loss: 3417580288.0000 - val_mae: 50124.0312\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3402323456.0000 - mae: 50109.9805 - val_loss: 3404888576.0000 - val_mae: 50062.6797\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3391535104.0000 - mae: 50051.6953 - val_loss: 3394463744.0000 - val_mae: 50010.5391\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3382540288.0000 - mae: 50003.0664 - val_loss: 3386756352.0000 - val_mae: 49971.2344\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3374702592.0000 - mae: 49961.0156 - val_loss: 3378969344.0000 - val_mae: 49936.0117\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3368391168.0000 - mae: 49924.4688 - val_loss: 3374180608.0000 - val_mae: 49910.8086\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3362598144.0000 - mae: 49892.0195 - val_loss: 3368991488.0000 - val_mae: 49883.3008\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3357436160.0000 - mae: 49861.2188 - val_loss: 3364766464.0000 - val_mae: 49858.9805\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3353131776.0000 - mae: 49833.6914 - val_loss: 3361488896.0000 - val_mae: 49842.7344\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3349224192.0000 - mae: 49812.3281 - val_loss: 3358082304.0000 - val_mae: 49826.3867\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3345243904.0000 - mae: 49788.4102 - val_loss: 3355955968.0000 - val_mae: 49816.1406\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3341657600.0000 - mae: 49769.2266 - val_loss: 3353399808.0000 - val_mae: 49803.1953\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3338900992.0000 - mae: 49748.7812 - val_loss: 3351881728.0000 - val_mae: 49795.1836\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3335833856.0000 - mae: 49730.1836 - val_loss: 3348351232.0000 - val_mae: 49781.4766\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3333047296.0000 - mae: 49715.5312 - val_loss: 3346334976.0000 - val_mae: 49772.4219\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3330513408.0000 - mae: 49698.3867 - val_loss: 3345213952.0000 - val_mae: 49764.5781\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3328340480.0000 - mae: 49691.1758 - val_loss: 3343416320.0000 - val_mae: 49755.0859\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3326266368.0000 - mae: 49674.7539 - val_loss: 3342062336.0000 - val_mae: 49747.5664\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3324077056.0000 - mae: 49657.9844 - val_loss: 3340909056.0000 - val_mae: 49739.3047\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3322418176.0000 - mae: 49651.8867 - val_loss: 3339830784.0000 - val_mae: 49731.2188\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3320368128.0000 - mae: 49638.2383 - val_loss: 3338626048.0000 - val_mae: 49723.0352\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3319108608.0000 - mae: 49628.5664 - val_loss: 3337772800.0000 - val_mae: 49717.3438\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3317095168.0000 - mae: 49618.1602 - val_loss: 3336627200.0000 - val_mae: 49709.4648\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3316140032.0000 - mae: 49608.7891 - val_loss: 3336092416.0000 - val_mae: 49706.9414\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3314725376.0000 - mae: 49599.1406 - val_loss: 3334429440.0000 - val_mae: 49700.2852\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3313473024.0000 - mae: 49594.6914 - val_loss: 3333943040.0000 - val_mae: 49694.0547\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3312006656.0000 - mae: 49582.7852 - val_loss: 3333773824.0000 - val_mae: 49691.2344\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3311386880.0000 - mae: 49573.8398 - val_loss: 3333371392.0000 - val_mae: 49687.6055\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3309712128.0000 - mae: 49565.0586 - val_loss: 3333133056.0000 - val_mae: 49683.4102\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3308515072.0000 - mae: 49559.1445 - val_loss: 3332029184.0000 - val_mae: 49678.4102\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3307785984.0000 - mae: 49554.3516 - val_loss: 3330890240.0000 - val_mae: 49676.0586\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3306547456.0000 - mae: 49544.7500 - val_loss: 3331159808.0000 - val_mae: 49673.7148\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3305360384.0000 - mae: 49541.3164 - val_loss: 3329489408.0000 - val_mae: 49666.4961\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3304747776.0000 - mae: 49530.1562 - val_loss: 3329103360.0000 - val_mae: 49663.5039\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3304082432.0000 - mae: 49531.0898 - val_loss: 3330004992.0000 - val_mae: 49663.1094\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3303141120.0000 - mae: 49518.2461 - val_loss: 3329147648.0000 - val_mae: 49661.0703\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3302063872.0000 - mae: 49513.0742 - val_loss: 3328105472.0000 - val_mae: 49656.0508\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3301669632.0000 - mae: 49509.9805 - val_loss: 3327628032.0000 - val_mae: 49654.0859\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3300959744.0000 - mae: 49505.3867 - val_loss: 3327589632.0000 - val_mae: 49652.5469\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3299895552.0000 - mae: 49500.1055 - val_loss: 3327787008.0000 - val_mae: 49652.5898\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3299252736.0000 - mae: 49492.5117 - val_loss: 3327175168.0000 - val_mae: 49648.1953\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3298723072.0000 - mae: 49489.9844 - val_loss: 3327691008.0000 - val_mae: 49649.4766\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3297768448.0000 - mae: 49482.3164 - val_loss: 3327151616.0000 - val_mae: 49644.2617\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3297517312.0000 - mae: 49477.9492 - val_loss: 3325711360.0000 - val_mae: 49640.7734\n",
      "Epoch 61/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3296804864.0000 - mae: 49472.8633 - val_loss: 3325005056.0000 - val_mae: 49638.4102\n",
      "Epoch 62/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3295888896.0000 - mae: 49467.4844 - val_loss: 3326168576.0000 - val_mae: 49641.9531\n",
      "Epoch 63/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3295361792.0000 - mae: 49456.8789 - val_loss: 3326711808.0000 - val_mae: 49640.2461\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3295050752.0000 - mae: 49465.3906 - val_loss: 3325285888.0000 - val_mae: 49638.1055\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3294688768.0000 - mae: 49457.1953 - val_loss: 3324408320.0000 - val_mae: 49634.8047\n",
      "Epoch 66/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3293579520.0000 - mae: 49449.6211 - val_loss: 3325097728.0000 - val_mae: 49635.4766\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3293056256.0000 - mae: 49448.0781 - val_loss: 3325199104.0000 - val_mae: 49635.5312\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3292830720.0000 - mae: 49445.6094 - val_loss: 3324745472.0000 - val_mae: 49632.8633\n",
      "Epoch 69/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3291959040.0000 - mae: 49438.5156 - val_loss: 3324580096.0000 - val_mae: 49632.0117\n",
      "Epoch 70/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3291964672.0000 - mae: 49438.3789 - val_loss: 3324038144.0000 - val_mae: 49629.7969\n",
      "Epoch 71/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3291406080.0000 - mae: 49432.1133 - val_loss: 3323699968.0000 - val_mae: 49629.2539\n",
      "Epoch 72/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3290629632.0000 - mae: 49426.6211 - val_loss: 3325088256.0000 - val_mae: 49630.8008\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3290506496.0000 - mae: 49426.6445 - val_loss: 3325790464.0000 - val_mae: 49632.1562\n",
      "Epoch 74/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3289913856.0000 - mae: 49424.0352 - val_loss: 3324465920.0000 - val_mae: 49629.1289\n",
      "Epoch 75/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3289266176.0000 - mae: 49416.5156 - val_loss: 3323759872.0000 - val_mae: 49626.4258\n",
      "Epoch 76/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3288928512.0000 - mae: 49415.4883 - val_loss: 3324264192.0000 - val_mae: 49628.1797\n",
      "Epoch 77/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3288493056.0000 - mae: 49411.5898 - val_loss: 3324112384.0000 - val_mae: 49629.0586\n",
      "Epoch 78/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3288270336.0000 - mae: 49405.9102 - val_loss: 3323762176.0000 - val_mae: 49624.8633\n",
      "Epoch 79/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3287973632.0000 - mae: 49411.7734 - val_loss: 3321905152.0000 - val_mae: 49622.4766\n",
      "Epoch 80/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3287621376.0000 - mae: 49401.9102 - val_loss: 3322585344.0000 - val_mae: 49622.5156\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3286905856.0000 - mae: 49394.6445 - val_loss: 3323943936.0000 - val_mae: 49623.6484\n",
      "Epoch 82/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3286508800.0000 - mae: 49397.9336 - val_loss: 3323107328.0000 - val_mae: 49620.9961\n",
      "Epoch 83/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3285996544.0000 - mae: 49391.3711 - val_loss: 3322647552.0000 - val_mae: 49620.4648\n",
      "Epoch 84/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3286012672.0000 - mae: 49389.7656 - val_loss: 3323264256.0000 - val_mae: 49619.7109\n",
      "Epoch 85/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3285451776.0000 - mae: 49386.6914 - val_loss: 3323207936.0000 - val_mae: 49619.6836\n",
      "Epoch 86/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3284834816.0000 - mae: 49382.1250 - val_loss: 3322316288.0000 - val_mae: 49616.3633\n",
      "Epoch 87/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3284534784.0000 - mae: 49379.0234 - val_loss: 3322788608.0000 - val_mae: 49620.0469\n",
      "Epoch 88/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3284101120.0000 - mae: 49377.0469 - val_loss: 3321512192.0000 - val_mae: 49617.1797\n",
      "Epoch 89/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3284214784.0000 - mae: 49372.1953 - val_loss: 3323376384.0000 - val_mae: 49620.6133\n",
      "Epoch 90/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3283511296.0000 - mae: 49370.9141 - val_loss: 3321994496.0000 - val_mae: 49616.7305\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3283025152.0000 - mae: 49371.4844 - val_loss: 3321984512.0000 - val_mae: 49617.7461\n",
      "Epoch 92/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3282706176.0000 - mae: 49363.1719 - val_loss: 3322183424.0000 - val_mae: 49618.3555\n",
      "Epoch 93/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3282368512.0000 - mae: 49360.5938 - val_loss: 3322526976.0000 - val_mae: 49618.8008\n",
      "Epoch 94/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3282359808.0000 - mae: 49364.3281 - val_loss: 3322044160.0000 - val_mae: 49617.8359\n",
      "Epoch 95/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3281609984.0000 - mae: 49357.0156 - val_loss: 3321883648.0000 - val_mae: 49617.8438\n",
      "Epoch 96/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3281698560.0000 - mae: 49358.6406 - val_loss: 3321296896.0000 - val_mae: 49616.2891\n",
      "Epoch 97/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3281083392.0000 - mae: 49356.6602 - val_loss: 3321949952.0000 - val_mae: 49619.4414\n",
      "Epoch 98/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3280678400.0000 - mae: 49352.4961 - val_loss: 3321477888.0000 - val_mae: 49618.1250\n",
      "Epoch 99/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3280567296.0000 - mae: 49350.0234 - val_loss: 3322136576.0000 - val_mae: 49620.0898\n",
      "Epoch 100/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3280275456.0000 - mae: 49349.1562 - val_loss: 3321227520.0000 - val_mae: 49616.3008\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57181d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9192), started 0:00:53 ago. (Use '!kill 9192' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d4958eeea0633bcd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d4958eeea0633bcd\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load extension for tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir regression_logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a104fdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3367727872.0000 - mae: 50141.6094\n",
      "Test MAE: 50141.609375\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test MAE: {test_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "305ffff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## Save the model\n",
    "model.save('salary_regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
